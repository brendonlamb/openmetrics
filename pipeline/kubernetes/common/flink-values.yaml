# Uses values for this project.
# https://github.com/riskfocus/helm-charts-public/tree/master/flink

nameOverride: "flink"
fullnameOverride: "flink"

image:
  repository: "flink"
  tag: 1.14.4-java11
  pullPolicy: IfNotPresent
imagePullSecrets: []

# For general configuration
flink:
  # logging
  # TODO - change logging level.
  logging:
    log4j_properties: |+
      # This affects logging for both user code and Flink
      rootLogger.level = INFO
      rootLogger.appenderRef.console.ref = ConsoleAppender
      rootLogger.appenderRef.rolling.ref = RollingFileAppender

      # Uncomment this if you want to _only_ change Flink's logging
      #logger.flink.name = org.apache.flink
      #logger.flink.level = INFO

      # The following lines keep the log level of common libraries/connectors on
      # log level INFO. The root logger does not override this. You have to manually
      # change the log levels here.
      logger.akka.name = akka
      logger.akka.level = INFO
      logger.kafka.name= org.apache.kafka
      logger.kafka.level = INFO
      logger.hadoop.name = org.apache.hadoop
      logger.hadoop.level = INFO
      logger.zookeeper.name = org.apache.zookeeper
      logger.zookeeper.level = INFO

      # Log all infos to the console
      appender.console.name = ConsoleAppender
      appender.console.type = CONSOLE
      appender.console.layout.type = PatternLayout
      appender.console.layout.pattern = %d{yyyy-MM-dd HH:mm:ss,SSS} %-5p %-60c %x - %m%n

      # Log all infos in the given rolling file
      appender.rolling.name = RollingFileAppender
      appender.rolling.type = RollingFile
      appender.rolling.append = false
      appender.rolling.fileName = ${sys:log.file}
      appender.rolling.filePattern = ${sys:log.file}.%i
      appender.rolling.layout.type = PatternLayout
      appender.rolling.layout.pattern = %d{yyyy-MM-dd HH:mm:ss,SSS} %-5p %-60c %x - %m%n
      appender.rolling.policies.type = Policies
      appender.rolling.policies.size.type = SizeBasedTriggeringPolicy
      appender.rolling.policies.size.size=100MB
      appender.rolling.strategy.type = DefaultRolloverStrategy
      appender.rolling.strategy.max = 10

      # Suppress the irrelevant (wrong) warnings from the Netty channel handler
      logger.netty.name = org.apache.flink.shaded.akka.org.jboss.netty.channel.DefaultChannelPipeline
      logger.netty.level = OFF
  # monitoring is exporting metrics in Prometheus format
  monitoring:
    enabled: false
  workDir: /opt/flink
  state:
    # backend for state. Available options: filesystem, rocksdb, memory; empty - for default(memory)
    # TODO - change the backend.
    backend: rocksdb
    # These values are default excludes file pathes
    # https://ci.apache.org/projects/flink/flink-docs-stable/dev/stream/state/checkpointing.html#related-config-options
    params: |+
      state.backend.async: true
      state.backend.incremental: true
      taskmanager.memory.managed.fraction: 0.7
      state.backend.local-recovery: true
      state.checkpoints.num-retained: 1
      taskmanager.state.local.root-dirs: /flink_state/local-recovery
      # At 256mb, we regularly hit Metaspace OOMs.
      taskmanager.memory.jvm-metaspace.size: 384mb
    # https://ci.apache.org/projects/flink/flink-docs-stable/ops/state/state_backends.html#rocksdb-state-backend-config-options
    # * state.backend.rocksdb.localdir doesn't have a prefix - file://
    rocksdb: |+
      state.backend.rocksdb.checkpoint.transfer.thread.num: 1
      state.backend.rocksdb.localdir: /flink_state/rocksdb
      state.backend.rocksdb.options-factory: org.apache.flink.contrib.streaming.state.DefaultConfigurableOptionsFactory
      state.backend.rocksdb.predefined-options: DEFAULT
      state.backend.rocksdb.timer-service.factory: ROCKSDB
      state.backend.rocksdb.ttl.compaction.filter.enabled: false
# extraEnvs passes envs to both Jobmanagers and Taskmanager
# for example
# extraEnvs:
#  - name: KAFKA_BOOTSTRAP_SERVERS
#    value: dest-kafka-bootstrap:9092
#
extraEnvs: []

jobmanager:
  # Statefulset option will create Jobmanager as a StatefulSet
  statefulset: true
  # Init containers
  initContainers: {}
  # Example
  #  test:
  #    image: busybox:1.28
  #    command:
  #      - /bin/sh
  #      - -c
  #      - "echo test"
  # highAvailability configuration based on zookeeper
  highAvailability:
    # To enable high availability:
    # 1. Change this to true.
    # 2. Uncomment the lines after the 'enabled' line.
    # 3. Increase jobmanager.replicaCount to 2.
    enabled: false
    # zookeeperConnect: "zookeeper:{{ .Values.zookeeper.env.ZOO_PORT }}"
    # zookeeperRootPath: /flink
    # clusterId: /flink
    # # storageDir for Jobmanagers. DFS expected.
    # # Docs - Storage directory (required): JobManager metadata is persisted in the file system storageDir and only a pointer to this state is stored in ZooKeeper
    # storageDir: s3a://promoted-event-logs/flink/jobmanager
    # # syncPort is a rpc port in HA configuration
    # syncPort: 6150
    # # command for HA configuration
    # # this trick with sed required because taskmanagers read jobmanager.rpc.address from Zookeeper.
    # # For configuration with one jobmanager (it's enough stable because Kubernetes will restart Jobmanager on falures)
    # # 'sed' can be changed to use flink service name, e.g. {{ include "flink.name" . }}-jobmanager
    # command: >-
    #   sed 's/REPLACE_HOSTNAME/'${FLINK_POD_IP}'/'
    #   $FLINK_HOME/conf/flink-conf.yaml.tpl > $FLINK_HOME/conf/flink-conf.yaml &&
    #   $FLINK_HOME/bin/jobmanager.sh start-foreground;

  # Additional param for JVM to support security.properties override
  # check configMap for more information
  jvmArgs: "-Djava.security.properties={{ .Values.flink.workDir }}/conf/security.properties"
  # extraEnvs passes envs to Jobmanagers
  extraEnvs: []
  ports:
    rpc: 6123
    # blob port uses for Liveness probe
    blob: 6124
    ui: 8081
  replicaCount: 1
  # heapSize params for Jobmanager
  # keep in mind that Flink can use offheap memory
  # e.g. in case of checkpoint usage
  heapSize: 1g
  resources: {}
  # Example
  #    limits:
  #      cpu: 3800m
  #      memory: 8000Mi
  #
  # TODO - do sha checks on these downloads.
  additionalCommand: >-
    mkdir -p /opt/flink/plugins/s3-fs-hadoop/ &&
    cp /opt/flink/opt/flink-s3-fs-hadoop-*.jar /opt/flink/plugins/s3-fs-hadoop/ &&
    wget https://repo1.maven.org/maven2/com/github/oshi/oshi-core/3.4.0/oshi-core-3.4.0.jar
    -O /opt/flink/lib/oshi-core-3.4.0.jar &&
    wget https://repo1.maven.org/maven2/net/java/dev/jna/jna/5.4.0/jna-5.4.0.jar
    -O /opt/flink/lib/jna-5.4.0.jar &&
    wget https://repo1.maven.org/maven2/net/java/dev/jna/jna-platform/5.4.0/jna-platform-5.4.0.jar
    -O /opt/flink/lib/jna-platform-5.4.0.jar
  command: >-
    export LD_PRELOAD=$LD_PRELOAD:/usr/lib/x86_64-linux-gnu/libjemalloc.so;
    cp $FLINK_HOME/conf/flink-conf.yaml.tpl $FLINK_HOME/conf/flink-conf.yaml &&
    $FLINK_HOME/bin/jobmanager.sh start;
    while :;
    do
    if [[ -f $(find log -name '*jobmanager*.log' -print -quit) ]];
    then tail -f -n +1 log/*jobmanager*.log;
    fi;
    done
  service:
    type: ClusterIP
    annotations: {}
    # rest is additional service which exposes only HTTP port
    # can be using for cases of using exposeController
    rest:
      enabled: true
      annotations: {}
    headless:
      annotations: {}
  nodeSelector: {}
  affinity: {}
  tolerations: []
  persistent:
    enabled: true
    storageClass:
    size: 1Gi
    mountPath: "/flink_state"
  podManagementPolicy: Parallel
  annotations: {}
  # Example
  #  "cluster-autoscaler.kubernetes.io/safe-to-evict": "false"
  serviceAccount:
    # Specifies whether a ServiceAccount should be created
    create: true
    # The name of the ServiceAccount to use.
    # If not set and create is true, a name is generated using the fullname template
    name:
  #livenessProbe will conduct checks for rpc port as tcpSocket probe
  livenessProbe:
    initialDelaySeconds: 10
    periodSeconds: 15
  readinessProbe:
    periodSeconds: 10
    initialDelaySeconds: 20
  podAnnotations: {}

taskmanager:
  # Statefulset option will create Taskmanager as a StatefulSet
  # A necessary option for Persistent
  statefulset: true
  # Additional param for JVM to support security.properties override
  # check configMap for more information
  jvmArgs: "-Djava.security.properties={{ .Values.flink.workDir }}/conf/security.properties"
  # extraEnvs passes envs to Taskmanagers
  extraEnvs: []
  ports:
    rpc: 6122
  # TODO - optimize this for production.
  replicaCount: 1
  # TODO - optimize this for production.
  numberOfTaskSlots: 36
  additionalCommand: >-
    mkdir -p /opt/flink/plugins/s3-fs-hadoop/ &&
    cp /opt/flink/opt/flink-s3-fs-hadoop-*.jar /opt/flink/plugins/s3-fs-hadoop/ &&
    wget https://repo1.maven.org/maven2/com/github/oshi/oshi-core/3.4.0/oshi-core-3.4.0.jar
    -O /opt/flink/lib/oshi-core-3.4.0.jar &&
    wget https://repo1.maven.org/maven2/net/java/dev/jna/jna/5.4.0/jna-5.4.0.jar
    -O /opt/flink/lib/jna-5.4.0.jar &&
    wget https://repo1.maven.org/maven2/net/java/dev/jna/jna-platform/5.4.0/jna-platform-5.4.0.jar
    -O /opt/flink/lib/jna-platform-5.4.0.jar
  command: >-
    export LD_PRELOAD=$LD_PRELOAD:/usr/lib/x86_64-linux-gnu/libjemalloc.so;
    $FLINK_HOME/bin/taskmanager.sh start;
    while :;
    do
    if [[ -f $(find log -name '*taskmanager*.log' -print -quit) ]];
    then tail -f -n +1 log/*taskmanager*.log;
    fi;
    done
  service:
    type: ClusterIP
  nodeSelector: {}
  affinity: {}
  tolerations: []
  persistent:
    enabled: true
    storageClass:
    mountPath: "/flink_state"
  podManagementPolicy: Parallel
  annotations:
    "cluster-autoscaler.kubernetes.io/safe-to-evict": "false"
  serviceAccount:
    # Specifies whether a ServiceAccount should be created
    create: true
    # The name of the ServiceAccount to use.
    # If not set and create is true, a name is generated using the fullname template
    name:
  #livenessProbe will conduct checks for rpc port as tcpSocket probe
  livenessProbe:
    initialDelaySeconds: 30
    periodSeconds: 60
  podAnnotations: {}

ingress:
  enabled: false
  annotations: {}
  path: /
  hosts: []
  tls: []

prometheus:
  # serviceMonitor provides service discovery for prometheus operatored installations
  serviceMonitor:
    enabled: false
    namespace:
    interval: 5s
    selector:
      # According to default selector for prometheus operator
      prometheus: kube-prometheus

zookeeper:
  enabled: false
  replicaCount: 3
  env:
    ZK_HEAP_SIZE: "1G"
    ZOO_PORT: 2181
  resources:
    limits:
      cpu: 400m
      memory: 1256Mi
  persistence:
    enabled: true
