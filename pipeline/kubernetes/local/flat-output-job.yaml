apiVersion: batch/v1
kind: Job
metadata:
  name: flat-output-job
spec:
  backoffLimit: 0
  template:
    spec:
      containers:
      - name: client
        image: bazel/pipeline/src/main/java/ai/promoted/metrics/logprocessor/job/join:FlatOutputJob_image
        env:
        - name: JOB_MANAGER_RPC_ADDRESS
          value: jobmanager
        # If you want to restart from a savepoint, add this after "run" ["-s", "s3a://promoted-event-logs/savepoints/savepoint-{id}"]
        command: ["flink", "run", "-d", "/opt/FlatOutputJob_deploy.jar"]
        args: [
          "--s3Bucket=promoted-event-logs",
          "--jobLabel=blue",
          "--sideOutputDebugLogging",
          "--startFromEarliest",
          # User property "is_host" - ccc
          "--nonBuyerUserSparseHash=6102540093495235004",
          # User property "is_staff" - ccc
          "--nonBuyerUserSparseHash=4078401918190321518",

          "--parallelism=1",
          "--maxParallelism=1",

          # Example flags to enable content joins.
          # "--contentApiRootUrl=http://ee1a-67-168-60-51.ngrok.io/",
          # "--contentApiKey=xyz",
          # "--contentApiSecretName=example-prod-content",
          # "--region=us-east-1",
          # Fields from the fake data generator.
          # "--contentIdFieldKeys=itemId",
          # "--contentIdFieldKeys=storeId",
          # "--contentIdFieldKeys=promotionId",

          # For local development, we want to periodically update the watermark.
          "--procAndEventWatermarkGenerator",
          "--watermarkIdlenessProcessingTimeTrailingDuration=PT1M",
          "--checkpointInterval=PT1M",

          # Keep the out of order times small to reduce resources in dev.
          "--flatResponseInsertionGapDuration=PT1M",
          "--combineDeliveryLogWindow=PT5S",
          "--viewInsertionJoinMax=PT20S",
          "--insertionImpressionJoinMax=PT20S",
          "--impressionActionJoinMax=PT20S"
        ]
        # We use specific mounts so we can map in log4j-cli.properties.
        # Otherwise, we need to modify the Helm chart directly.
        # Long-term, we the Flink client jobs should not reuse the config map.
        volumeMounts:
        - name: flink-config
          mountPath: /opt/flink/conf/flink-conf.yaml
          subPath: flink-conf.yaml
        - name: flink-config
          mountPath: /opt/flink/conf/flink-conf-taskmanager.yaml
          subPath: flink-conf-taskmanager.yaml
        - name: flink-config
          mountPath: /opt/flink/conf/log4j.properties
          subPath: log4j.properties
        - name: flink-config
          mountPath: /opt/flink/conf/security.properties
          subPath: security.properties
        - name: flink-cli-config
          mountPath: /opt/flink/conf/log4j-cli.properties
          subPath: log4j-cli.properties
      restartPolicy: Never
      serviceAccountName: ""
      volumes:
      - name: flink-config
        configMap:
          name: flink-config
          items:
            - key: flink-conf.yaml
              path: flink-conf.yaml
            - key: flink-conf-taskmanager.yaml
              path: flink-conf-taskmanager.yaml
            - key: log4j.properties
              path: log4j.properties
            - key: security.properties
              path: security.properties
      - name: flink-cli-config
        configMap:
          name: flink-cli-config
          items:
            - key: log4j-cli.properties
              path: log4j-cli.properties
status: {}
