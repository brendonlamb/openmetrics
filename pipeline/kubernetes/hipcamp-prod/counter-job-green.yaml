apiVersion: batch/v1
kind: Job
metadata:
  name: counter-job-green
spec:
  backoffLimit: 0
  template:
    spec:
      containers:
      - name: client
        image: 055315558257.dkr.ecr.us-east-1.amazonaws.com/prm-metrics-counter-job:63ecec65
        imagePullPolicy: "Always"
        env:
        - name: JOB_MANAGER_RPC_ADDRESS
          value: jobmanager
        command: ["flink", "run", "-d", "/opt/CounterJob_deploy.jar"]
        args: [
          "--kafkaSecurityProtocol=SSL",
          "--bootstrap.servers=b-2.ccc-prod-metrics.wil4fb.c12.kafka.us-east-1.amazonaws.com:9094,b-3.ccc-prod-metrics.wil4fb.c12.kafka.us-east-1.amazonaws.com:9094,b-1.ccc-prod-metrics.wil4fb.c12.kafka.us-east-1.amazonaws.com:9094",
          "--s3Bucket=ccc-prod-event-logs",
          "--jobLabel=green",

          # Some operators have larger parallelism.  See the backfill section.
          "--parallelism=1",
          "--maxParallelism=120",
          # Setting to 0 writes all values. Setting to -1 uses the process time.  
          "--counterOutputStartTimestamp=0",

          # DB num = {blue: 5, green: 0}
          "--counterService=redis://ccc-prod-metrics-counters-group.x1t9xw.ng.0001.use1.cache.amazonaws.com:6399/0",

          # Backfill flag
          # "--wipe",  ### IMPORTANT: uncomment when backfilling!
          # "--startFromEarliest",
          # "--checkpointInterval=PT10M",
          # Setting to -1 uses the process time.  Setting to 0 writes all values.
          # "--operatorParallelismMultiplier=count-hourly-event-platform-device=4",
          # "--operatorParallelismMultiplier=hset-hourly-event-platform-device=4",
          # "--operatorParallelismMultiplier=count-daily-event-platform-device=4",
          # "--operatorParallelismMultiplier=hset-daily-event-platform-device=4",
          # "--defaultSinkParallelism=2",
        ]
        # We use specific mounts so we can map in log4j-cli.properties.
        # Otherwise, we need to modify the Helm chart directly.
        # Long-term, we the Flink client jobs should not reuse the config map.
        volumeMounts:
        - name: flink-config
          mountPath: /opt/flink/conf/flink-conf.yaml
          subPath: flink-conf.yaml
        - name: flink-config
          mountPath: /opt/flink/conf/flink-conf-taskmanager.yaml
          subPath: flink-conf-taskmanager.yaml
        - name: flink-config
          mountPath: /opt/flink/conf/log4j.properties
          subPath: log4j.properties
        - name: flink-config
          mountPath: /opt/flink/conf/security.properties
          subPath: security.properties
        - name: flink-cli-config
          mountPath: /opt/flink/conf/log4j-cli.properties
          subPath: log4j-cli.properties
      restartPolicy: Never
      serviceAccountName: ""
      volumes:
      - name: flink-config
        configMap:
          name: flink-config
          items:
            - key: flink-conf.yaml
              path: flink-conf.yaml
            - key: flink-conf-taskmanager.yaml
              path: flink-conf-taskmanager.yaml
            - key: log4j.properties
              path: log4j.properties
            - key: security.properties
              path: security.properties
      - name: flink-cli-config
        configMap:
          name: flink-cli-config
          items:
            - key: log4j-cli.properties
              path: log4j-cli.properties
status: {}
