apiVersion: batch/v1
kind: Job
metadata:
  name: raw-output-job-green
spec:
  backoffLimit: 0
  template:
    spec:
      containers:
      - name: client
        image: 055315558257.dkr.ecr.us-east-1.amazonaws.com/prm-metrics-raw-output-job:prod-b873eb85
        imagePullPolicy: "Always"
        env:
        - name: JOB_MANAGER_RPC_ADDRESS
          value: jobmanager
        command: ["flink", "run", "-d", "/opt/RawOutputJob_deploy.jar"]
        args: [
          "--kafkaSecurityProtocol=SSL",
          "--bootstrap.servers=b-1.eeeprodmetrics.wm1fi5.c23.kafka.us-east-1.amazonaws.com:9094,b-2.eeeprodmetrics.wm1fi5.c23.kafka.us-east-1.amazonaws.com:9094,b-3.eeeprodmetrics.wm1fi5.c23.kafka.us-east-1.amazonaws.com:9094",
          "--s3Bucket=eee-prod-event-logs",
          "--jobLabel=green",

          "--writeLogUserUserEventsToKafka",

          "--startFromEarliest",
          "--parallelism=6",
          "--maxParallelism=120",
          # Just have one of these operators.
          "--operatorParallelismMultiplier=keep-first-log-user-user=0.25",
          "--operatorParallelismMultiplier=keep-first-cohort-membership=0.25",
          "--operatorParallelismMultiplier=clear-cohort-membership-user-id=0.25",
          "--operatorParallelismMultiplier=keep-first-view=0.25",
          "--operatorParallelismMultiplier=clear-view-user-id=0.25",
          "--operatorParallelismMultiplier=keep-first-auto-view=0.25",
          "--operatorParallelismMultiplier=clear-auto-view-user-id=0.25",
          "--operatorParallelismMultiplier=keep-first-impression=0.25",
          "--operatorParallelismMultiplier=clear-impression-user-id=0.25",
          "--operatorParallelismMultiplier=keep-first-action=0.25",
          "--operatorParallelismMultiplier=clear-action-user-id=0.25",
          "--operatorParallelismMultiplier=sink-s3-raw-log-request=1",
          "--operatorParallelismMultiplier=sink-s3-raw-delivery-log=1",
        ]
        # We use specific mounts so we can map in log4j-cli.properties.
        # Otherwise, we need to modify the Helm chart directly.
        # Long-term, we the Flink client jobs should not reuse the config map.
        volumeMounts:
        - name: flink-config
          mountPath: /opt/flink/conf/flink-conf.yaml
          subPath: flink-conf.yaml
        - name: flink-config
          mountPath: /opt/flink/conf/flink-conf-taskmanager.yaml
          subPath: flink-conf-taskmanager.yaml
        - name: flink-config
          mountPath: /opt/flink/conf/log4j.properties
          subPath: log4j.properties
        - name: flink-config
          mountPath: /opt/flink/conf/security.properties
          subPath: security.properties
        - name: flink-cli-config
          mountPath: /opt/flink/conf/log4j-cli.properties
          subPath: log4j-cli.properties
      restartPolicy: Never
      serviceAccountName: ""
      volumes:
      - name: flink-config
        configMap:
          name: flink-config
          items:
            - key: flink-conf.yaml
              path: flink-conf.yaml
            - key: flink-conf-taskmanager.yaml
              path: flink-conf-taskmanager.yaml
            - key: log4j.properties
              path: log4j.properties
            - key: security.properties
              path: security.properties
      - name: flink-cli-config
        configMap:
          name: flink-cli-config
          items:
            - key: log4j-cli.properties
              path: log4j-cli.properties
status: {}
