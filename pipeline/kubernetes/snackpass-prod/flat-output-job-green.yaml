apiVersion: batch/v1
kind: Job
metadata:
  name: flat-output-job-green
spec:
  backoffLimit: 0
  template:
    spec:
      containers:
      - name: client
        image: 055315558257.dkr.ecr.us-east-1.amazonaws.com/prm-metrics-flat-output-job:518655f9
        imagePullPolicy: "Always"
        env:
        - name: JOB_MANAGER_RPC_ADDRESS
          value: jobmanager
        command: ["flink", "run", "-d", "/opt/FlatOutputJob_deploy.jar"]
        args: [
          "--kafkaSecurityProtocol=SSL",
          "--bootstrap.servers=b-3.bbb-prod-metrics.llwzts.c3.kafka.us-east-2.amazonaws.com:9094,b-1.bbb-prod-metrics.llwzts.c3.kafka.us-east-2.amazonaws.com:9094,b-2.bbb-prod-metrics.llwzts.c3.kafka.us-east-2.amazonaws.com:9094",
          "--s3Bucket=bbb-prod-event-logs",
          "--jobLabel=green",

          "--startFromEarliest",

          # Join actions to Request Insertions with matching storeId properties.
          "--contentIdFieldKeys=storeId",

          # Can go up to 24 parallelism for the core join operators.
          "--parallelism=1",
          # 360 = Dan wanted a number larger than 120 in crease we wanted to scale up past 120 for backfill.
          "--maxParallelism=360",
          # Scale these operators differently from parallelism.
          "--defaultSinkParallelismMultiplier=0.6",
          "--operatorParallelismMultiplier=join-insertion-impressions=4",
          "--operatorParallelismMultiplier=merge-impression-details=4",

          # TODO - remove after the next binary is rolled out.
          "--viewInsertionJoinMax=PT0S",
          "--insertionImpressionJoinMax=PT0S",
          "--impressionActionJoinMax=PT0S",
          # 2022-08-13 = bbb's logging delay is a little slower than other customers.
          # A slightly longer combine window reduces the rate of not combining.
          # https://docs.google.com/spreadsheets/d/17uXe2Dglf6WLJ9yN0cGS2xFykI-XS_gymWCNmJjk6D0/edit#gid=0
          "--combineDeliveryLogWindow=PT2S",
        ]
        # We use specific mounts so we can map in log4j-cli.properties.
        # Otherwise, we need to modify the Helm chart directly.
        # Long-term, we the Flink client jobs should not reuse the config map.
        volumeMounts:
        - name: flink-config
          mountPath: /opt/flink/conf/flink-conf.yaml
          subPath: flink-conf.yaml
        - name: flink-config
          mountPath: /opt/flink/conf/flink-conf-taskmanager.yaml
          subPath: flink-conf-taskmanager.yaml
        - name: flink-config
          mountPath: /opt/flink/conf/log4j.properties
          subPath: log4j.properties
        - name: flink-config
          mountPath: /opt/flink/conf/security.properties
          subPath: security.properties
        - name: flink-cli-config
          mountPath: /opt/flink/conf/log4j-cli.properties
          subPath: log4j-cli.properties
      restartPolicy: Never
      serviceAccountName: ""
      volumes:
      - name: flink-config
        configMap:
          name: flink-config
          items:
            - key: flink-conf.yaml
              path: flink-conf.yaml
            - key: flink-conf-taskmanager.yaml
              path: flink-conf-taskmanager.yaml
            - key: log4j.properties
              path: log4j.properties
            - key: security.properties
              path: security.properties
      - name: flink-cli-config
        configMap:
          name: flink-cli-config
          items:
            - key: log4j-cli.properties
              path: log4j-cli.properties
status: {}
